{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IngridLaila/Conteudo_Didatico/blob/main/PySpark/Corre%C3%A7%C3%A3o_do_Exerc%C3%ADcio_aula_32.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wF9sOF_Tvar"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "zS1IE-GETyqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Para deixar a visualição das tabelas mais amigável\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "28fV3Q7gT1Ia",
        "outputId": "4b2d00ac-cc99-449c-ce58-0217359603cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fee047a1420>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://d7361a83efbd:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 1:\n",
        "Em ambiente PySpark crie uma tabela com quatro atributos sendo o\n",
        "primeiro qualitativo e os demais como quantitivos e dez registros\n",
        "(linhas para a tabela) sem registros nulos.\n",
        "'''\n",
        "\n",
        "'''\n",
        "Requisito 2:\n",
        "Em ambiente PySpark gerar um describe da tabela gerada no requisito anterior e recebê-lo\n",
        "com um df pyspark.\n",
        "'''\n",
        "\n",
        "'''\n",
        "Requisito 3:\n",
        "Em ambiente PySpark Selecionar a linha de desvio padrão do df gerar uma lista\n",
        "no ambiente python e armazená-lo com o nome sd\n",
        "'''\n",
        "\n",
        "'''\n",
        "Requisito 4:\n",
        "Em ambiente Python, manipular essa lista e a partir dela gerar uma lista\n",
        "com todos os valores numéricos da lista sd elevado ao quadrado e receber essa\n",
        "nova lista com o nome var\n",
        "'''\n",
        "\n",
        "'''\n",
        "Requisito 5:\n",
        "Transformar cada lista do requisito anterior em um df py spark\n",
        "'''\n",
        "\n",
        "'''\n",
        "Requisito 6:\n",
        "Em ambiente Pyspark juntar os dois dfs criados no requisito anterior e\n",
        "armazená-lo em um df pyspark chamado sd_var\n",
        "'''\n",
        "\n",
        "'''\n",
        "Requisito 7:\n",
        "Em ambiente Pyspark gerar uma junção do df da variância com o df das medidas\n",
        "'''\n",
        "\n",
        "'''\n",
        "Requisito 8:\n",
        "criar uma lista que contenha as modas de todos os atributos quantitativos\n",
        "do df inicial e inseri-la no df pyskar de mesdidas\n",
        "'''\n",
        "'''\n",
        "Requisito 9:\n",
        "Em ambiente Pyspark e Python e de forma semelahnte ao que foi feito nos\n",
        "requisitos anteriores\n",
        "\n",
        "Calcule e adicione ao df de medidas do pyspark as seguintes linhas com seus\n",
        "respectivos valores para as medidas:\n",
        "* Mediana\n",
        "* Q1\n",
        "* Q3\n",
        "* AT\n",
        "* AIQ\n",
        "* LS\n",
        "* LI\n",
        "\n",
        "'''\n"
      ],
      "metadata": {
        "id": "MKayJLwcUGr5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "02747a9a-4f31-4bf9-f5ce-215b5e177686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nRequisito 9:\\nEm ambiente Pyspark e Python e de forma semelahnte ao que foi feito nos\\nrequisitos anteriores\\n\\nCalcule e adicione ao df de medidas do pyspark as seguintes linhas com seus\\nrespectivos valores para as medidas:\\n* Mediana\\n* Q1\\n* Q3\\n* AT\\n* AIQ\\n* LS\\n* LI\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 1:\n",
        "Em ambiente PySpark crie uma tabela com quatro atributos sendo o\n",
        "primeiro qualitativo e os demais como quantitivos e dez registros\n",
        "(linhas para a tabela) sem registros nulos.\n",
        "'''\n",
        "\n",
        "'''\n",
        "Criação do schema que nada mais é do que o esqueleto da tabela\n",
        "'''\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.types import StructType,StructField,StringType,IntegerType,DoubleType # importando estrutura da tabela (structType)\n",
        "schema = StructType([ \\\n",
        "    StructField('nome',StringType(),True), \\\n",
        "    StructField('idade',IntegerType(),True), \\\n",
        "    StructField('altura',DoubleType(),True), \\\n",
        "    StructField('peso', DoubleType(), True), \\\n",
        "  ])\n",
        "\n",
        "'''\n",
        "Criação do objeto (nível Python) que contém as tuplas com os regitros que farão\n",
        "parte da tabela\n",
        "'''\n",
        "dados = [('Douglas',45,1.85,70.),\n",
        "    ('Daniela',7,1.23,22.),\n",
        "    ('Pedro',65,1.75,87.),\n",
        "    ('Maria',64,1.67,64.),\n",
        "    ('Eduardo',37,1.82,96.),\n",
        "    ('Ester',37,1.73,69.),\n",
        "    ('Tobias',18,1.82,96.),\n",
        "    ('Angela',32,1.72,70.),\n",
        "    ('Dagmar',35,1.65,63.),\n",
        "    ('Everaldo',37,1.82,96.)\n",
        "  ]\n",
        "'''\n",
        "Criação do dataframe py spark juntando a estutura da tabela com o objeto\n",
        "que contém os registros\n",
        "'''\n",
        "df_py = spark.createDataFrame(data=dados,schema=schema)\n",
        "'''\n",
        "Imprimir o schema do df_py\n",
        "'''\n",
        "df_py.printSchema()\n",
        "\n",
        "'''\n",
        "Mostrar o df_py\n",
        "'''\n",
        "df_py.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkFZ6gG5UKUY",
        "outputId": "74a1600b-4d08-4f87-d355-07859b439d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- nome: string (nullable = true)\n",
            " |-- idade: integer (nullable = true)\n",
            " |-- altura: double (nullable = true)\n",
            " |-- peso: double (nullable = true)\n",
            "\n",
            "+--------+-----+------+----+\n",
            "|    nome|idade|altura|peso|\n",
            "+--------+-----+------+----+\n",
            "| Douglas|   45|  1.85|70.0|\n",
            "| Daniela|    7|  1.23|22.0|\n",
            "|   Pedro|   65|  1.75|87.0|\n",
            "|   Maria|   64|  1.67|64.0|\n",
            "| Eduardo|   37|  1.82|96.0|\n",
            "|   Ester|   37|  1.73|69.0|\n",
            "|  Tobias|   18|  1.82|96.0|\n",
            "|  Angela|   32|  1.72|70.0|\n",
            "|  Dagmar|   35|  1.65|63.0|\n",
            "|Everaldo|   37|  1.82|96.0|\n",
            "+--------+-----+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 2:\n",
        "Em ambiente PySpark gerar um describe da tabela gerada no requisito anterior e\n",
        "recebê-lo com um df pyspark.\n",
        "'''\n",
        "medidas = df_py.describe()\n",
        "medidas.show()\n",
        "medidas = medidas.drop(\"nome\")\n",
        "medidas.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwHyBQZcUNJ8",
        "outputId": "94153272-965c-47ed-a55f-4878dae9df17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+------------------+-------------------+------------------+\n",
            "|summary|  nome|             idade|             altura|              peso|\n",
            "+-------+------+------------------+-------------------+------------------+\n",
            "|  count|    10|                10|                 10|                10|\n",
            "|   mean|  null|              37.7| 1.7060000000000002|              73.3|\n",
            "| stddev|  null|17.832866037491314|0.18056700818378885|22.603097132915217|\n",
            "|    min|Angela|                 7|               1.23|              22.0|\n",
            "|    max|Tobias|                65|               1.85|              96.0|\n",
            "+-------+------+------------------+-------------------+------------------+\n",
            "\n",
            "+-------+------------------+-------------------+------------------+\n",
            "|summary|             idade|             altura|              peso|\n",
            "+-------+------------------+-------------------+------------------+\n",
            "|  count|                10|                 10|                10|\n",
            "|   mean|              37.7| 1.7060000000000002|              73.3|\n",
            "| stddev|17.832866037491314|0.18056700818378885|22.603097132915217|\n",
            "|    min|                 7|               1.23|              22.0|\n",
            "|    max|                65|               1.85|              96.0|\n",
            "+-------+------------------+-------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 3:\n",
        "Em ambiente PySpark Selecionar a linha de desvio padrão do df gerar uma lista\n",
        "no ambiente python e armazená-lo com o nome sd\n",
        "'''\n",
        "sd = list(medidas.collect()[2])\n",
        "print(sd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOrPR9kYUPoD",
        "outputId": "c81c026c-950c-4abd-d914-53dc291637fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['stddev', '17.832866037491314', '0.18056700818378885', '22.603097132915217']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 4:\n",
        "Em ambiente Python, manipular essa lista e a partir dela gerar uma lista\n",
        "com todos os valores numéricos da lista sd elevado ao quadrado e receber essa\n",
        "nova lista com o nome var\n",
        "'''\n",
        "sd.pop(0)\n",
        "print(sd)\n",
        "var = []\n",
        "for i in range(len(sd)):\n",
        "  sd[i] = float(sd[i])\n",
        "  var.append(sd[i]**2)\n",
        "print(var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrsNpKPddKYM",
        "outputId": "9e4759dc-ddb8-4f9d-e430-f86f14865ea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['17.832866037491314', '0.18056700818378885', '22.603097132915217']\n",
            "[318.0111111111112, 0.03260444444444447, 510.9000000000001]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 5:\n",
        "Transformar cada lista do requisito anterior em um df py spark\n",
        "'''\n",
        "sd.insert(0,'desvio padrão')\n",
        "var.insert(0, 'variância')\n",
        "\n",
        "#sd = tuple(sd)\n",
        "#var = tuple(var)\n",
        "\n",
        "df_var = spark.createDataFrame([var])\n",
        "df_sd = spark.createDataFrame([sd],[\"summary\",\"idade\",\"altura\",\"peso\"])\n",
        "df_sd.show()\n",
        "df_var.show()\n",
        "df_var.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFc8vwjLkSPV",
        "outputId": "90501702-cbfe-48af-8752-384e919f2708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------------------+-------------------+------------------+\n",
            "|      summary|             idade|             altura|              peso|\n",
            "+-------------+------------------+-------------------+------------------+\n",
            "|desvio padrão|17.832866037491314|0.18056700818378885|22.603097132915217|\n",
            "+-------------+------------------+-------------------+------------------+\n",
            "\n",
            "+---------+-----------------+-------------------+-----------------+\n",
            "|       _1|               _2|                 _3|               _4|\n",
            "+---------+-----------------+-------------------+-----------------+\n",
            "|variância|318.0111111111112|0.03260444444444447|510.9000000000001|\n",
            "+---------+-----------------+-------------------+-----------------+\n",
            "\n",
            "root\n",
            " |-- _1: string (nullable = true)\n",
            " |-- _2: double (nullable = true)\n",
            " |-- _3: double (nullable = true)\n",
            " |-- _4: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 6:\n",
        "Em ambiente Pyspark juntar os dois dfs criados no requisito anterior e\n",
        "armazená-lo em um df pyspark chamado sd_var\n",
        "'''\n",
        "\n",
        "df_sd_var = df_sd.union(df_var)\n",
        "df_sd_var.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW66OlGIrd5F",
        "outputId": "48611be7-1411-4e6c-b8c1-39cba330d368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------------------+-------------------+------------------+\n",
            "|      summary|             idade|             altura|              peso|\n",
            "+-------------+------------------+-------------------+------------------+\n",
            "|desvio padrão|17.832866037491314|0.18056700818378885|22.603097132915217|\n",
            "|    variância| 318.0111111111112|0.03260444444444447| 510.9000000000001|\n",
            "+-------------+------------------+-------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Requisito 7:\n",
        "Em ambiente Pyspark fazer a inclusão do df da variância no df das medidas\n",
        "'''\n",
        "medidas = medidas.union(df_var)\n",
        "medidas.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8AOSWbWsrJq",
        "outputId": "407ea936-5b28-4a1e-c405-1e23c49a618d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------------+-------------------+------------------+\n",
            "|  summary|             idade|             altura|              peso|\n",
            "+---------+------------------+-------------------+------------------+\n",
            "|    count|                10|                 10|                10|\n",
            "|     mean|              37.7| 1.7060000000000002|              73.3|\n",
            "|   stddev|17.832866037491314|0.18056700818378885|22.603097132915217|\n",
            "|      min|                 7|               1.23|              22.0|\n",
            "|      max|                65|               1.85|              96.0|\n",
            "|variância| 318.0111111111112|0.03260444444444447| 510.9000000000001|\n",
            "+---------+------------------+-------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8NO_U2YWuYQu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}